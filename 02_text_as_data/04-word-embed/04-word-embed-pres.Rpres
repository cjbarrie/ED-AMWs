Word embedding
========================================================
author: Christopher Barrie 
width: 2500
height: 900
transition: none  
  website: https://cjbarrie.com  
  github: https://github.com/cjbarrie       
  Twitter: https://www.twitter.com/cbarrie

Word embedding
========================================================

- "you shall know a word by the company it keeps" (Firth, 1957)
    - Generates matrix of word vectors
      - where words closer together in vector space are more "similar" or "related"
      
How does it work?
========================================================

- Various approaches, including:
  - 1. SVD
  - 2. Neural network-based techniques like GloVe and Word2Vec
  
What do both approaches do?
========================================================

1. Define a context window
2. Looks at probabilities of word appearing near another word

========================================================

- Define a context window:

![Context window](images/window.png)
  
========================================================

- Looks at probabilities of word appearing near another word

```{r, echo= F}
library(Matrix)
library(tidyverse)

load("data/pmi_svd.RData")
load("data/pmi_matrix.RData")

head(pmi_matrix[1:6, 1:6])
```
  
    
Implementation: SVD approach
========================================================

- Data structure:
  - Word pair matrix with PMI (Pairwise mutual information)
  - where   PMI = log(P(x,y)/P(x)P(y))
  - and   P(x,y)   is the probability of word x appearing within a six-word window of word y
  - and   P(x)   is the probability of word x appearing in the whole corpus
  - and   P(y)   is the probability of word y appearing in the whole corpus
    
The resulting matrix structure will look something like this:
    
```{r ,echo=F}

head(pmi_matrix[1:6, 1:6])

```

Implementation: SVD approach
========================================================

And the resulting matrix object will take the following format:

```{r ,echo=F}

glimpse(pmi_matrix)

```

Implementation: neural-net GloVe approach
========================================================

<center>
<img src="images/skip_gram_mikolov.png" >
</center>

Extensions
========================================================

- "conText": from [Rodriguez et al.](https://github.com/prodriguezsosa/EmbeddingRegression) and dedicated R package [here](https://github.com/prodriguezsosa/conText)
- Concept mover's distance: see [Taylor and Stoltz](https://link.springer.com/article/10.1007/s42001-019-00048-6) and dedicated R package [here](https://github.com/dustinstoltz/CMDist)

Worksheets
========================================================

- [https://github.com/cjbarrie/ED-AMWs](https://github.com/cjbarrie/ED-AMWs)